# Neural-Network

## 学习笔记

1. ### 预备知识

- #### 数据操作

numpy pandas os

- #### 数据预处理

把训练数据化成方便读取的格式

- #### 线性代数

Y = W*X+b, 其中 W 和 X 都是矩阵，它们满足矩阵乘法原则，b 是列矩阵，他按照 torch 的广播机制和前者相加

- #### 自动微分

自动微分需要再定义变量（比如 x）的时候再后面添加，require_grad, 还需要其他的函数进行显示的 backward()以后才会被计算，这时候可以使用 x.grad 来进行调用

- #### 概率

pytorch 中有一个方法可以自动的批量进行随机模拟，产生具体的样本

2. ### 线性神经网络

- #### 线性回归

线性回归指的是是使用线性模型来对模型进行拟合

- #### 线性回归的从零开始实现

1. 数据迭代器（data_iter）用于获取一定 batch_size 的数据
2. 网络（net）用于具体的计算
3. 损失函数（loss）用于评估训练的准确度
4. 梯度下降函数（sgd）用于根据计算得到的梯度更新 w 已经 b 的值
5. epoch 表示训练的轮数

- #### 线性回归的简洁实现

- #### softmax 回归

主要区别于线性拟合的地方，在于使用的函数不相同，softmax 可以将结果映射成分类后的结果，而线性拟合的结果是连续的

- #### 图像分类数据集

这里主要介绍了图像分类数据集的预处理操作，他把 28 *28 的很多张图片转化成了 784*$(照片张数)的数据，然后写了一个迭代器用于获取每一次的训练数据

3. ### 多层感知器

- 多层感知机

它对多层感知机做了一个简单的介绍，它主要突出了上面的层的概念。

- #### 多层感知器的简洁实现

它和之前线性回归的整体框架是类似的，主要区别只在于它中间的层级结构更多了一些，计算更复杂了一些

- #### 模型选择与欠拟合、过拟合

多项式维度低会欠拟合，而过高则会过拟合

- #### 权重衰减

- #### 向前传播

- #### 训练神经网络

以上述简单网络为例：一方面，在前向传播期间计算正则项 [(4.7.5)](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/backprop.html#equation-eq-forward-s) 取决于模型参数和 的当前值。 它们是由优化算法根据最近迭代的反向传播给出的。 另一方面，反向传播期间参数 [(4.7.11)](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/backprop.html#equation-eq-backprop-j-h) 的梯度计算， 取决于由前向传播给出的隐藏变量

的当前值。

因此，在训练神经网络时，在初始化模型参数后， 我们交替使用前向传播和反向传播，利用反向传播给出的梯度来更新模型参数。 注意，反向传播重复利用前向传播中存储的中间值，以避免重复计算。 带来的影响之一是我们需要保留中间值，直到反向传播完成。 这也是训练比单纯的预测需要更多的内存（显存）的原因之一。 此外，这些中间值的大小与网络层的数量和批量的大小大致成正比。 因此，使用更大的批量来训练更深层次的网络更容易导致 *内存不足*（out of memory）错误。

- #### 数值稳定性和模型初始化

梯度消失 当 sigmoid 函数的输入很大或是很小时，它的梯度都会消失, 因此，更稳定的 ReLU 系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）

梯度爆炸 矩阵乘积发生爆炸。 当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛

- #### 参数初始化

- #####  默认初始化 使用正态分布来初始化权重值

- ##### Xavier 初始化 

- #### 分布偏移

训练集和测试集并不来自同一个分布。这就是所谓的分布偏移

在相应的假设条件下，可以在测试时检测并纠正协变量偏移和标签偏移。在测试时，不考虑这种偏移可能会成为问题

## mathematica 神经网络

mathematica 神经网络综述

https://reference.wolfram.com/language/tutorial/NeuralNetworksOverview.html

mathematica 神经网络简述

https://reference.wolfram.com/language/tutorial/NeuralNetworksIntroduction.html.zh?source = footer

## python 神经网络

李沐电子版教程

https://zh-v2.d2l.ai/

本地文件夹配套李沐教程

[文件夹](file:///home/yang/d2l-zh/pytorch/)

## pytorch 官网

官方文档

https://pytorch.org/docs/stable/index.html

官方网站

https://pytorch.org

## MXNet

[官方网站](https://www.nvidia.cn/glossary/data-science/mxnet/)

mxnet 是英伟达推出的一项机器语言学习框架，可以直接适用于英伟达的芯片，而且在 GPU 组训练上更加具有优势

## 相关比赛

### [kaggle](https://www.kaggle.com/)

这是一个当今流行举办机器学习比赛的平台， 每场比赛都以至少一个数据集为中心

#### 选手

[SZU Bayes](https://www.kaggle.com/bayes2003)

它来源于 [甲骨文公司](https://docs.oracle.com/cd/E28280_01/bi.1111/b32122/orbr_concepts1004.htm#RSBDR152)，它是房价预测比赛的第一名

## 专家

微信名称 望风