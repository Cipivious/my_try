反爬虫总结
==========

关于反爬虫，最重要的是观察网站采用的是什么反爬虫的策略

还有就是要善于使用搜索引擎，比如我最近遇到一个cloudfare的问题，我自己没有找到很好的解决方案，这个时候我不应该止步不前，而是应当善于寻求帮助，这次我的做法是从咸鱼上面找了一个人，让他帮助我排查然后解决了问题。但其实最关键的一步还是要学会用合适的关键词来进行搜索，比如这个搜索`cloudfare selenium`，就会出现下面的页面。然后其实只要点击第一个看进去，就可以发现uc这个专门的用来破除cloudfare的工具，这个搜索引擎的用法，可以值200块钱。其实知识付费最大的难点，不在于知识本身，而在于获取知识的方法。互联网上有很多的知识，只要善用互联网，善用搜索引擎，就可以发现一个巨大的宝库。

![image-20240729194140012](https://raw.githubusercontent.com/Cipivious/my_try/main/img/image-20240729194140012.png)

[反爬虫机制和破解方法汇总](https://cloud.tencent.com/developer/article/1032918)
-------------------------------------------------------------------------------

### 摘自网络

#### 什么是爬虫和反爬虫？

- **爬虫**：使用任何技术手段，批量获取网站信息的一种方式。
- **反爬虫**：使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。

#### 

![img](https://ask.qcloudimg.com/http-save/yehe-1227999/xa9bhuro7m.jpeg)

常见的反爬虫机制

- **通过UA 识别爬虫** 有些爬虫的UA是特殊的，与正常浏览器的不一样，可通过识别特征UA，直接封掉爬虫请求
- **设置IP访问频率，如果超过一定频率，弹出**[**验证码**](https://cloud.tencent.com/product/captcha?from_column=20065&from=20065) 如果输入正确的验证码，则放行，如果没有输入，则拉入禁止一段时间，如果超过禁爬时间，再次出发验证码，则拉入黑名单。当然根据具体的业务，为不同场景设置不同阈值，比如登陆用户和非登陆用户，请求是否含有refer。
- **通过并发识别爬虫** 有些爬虫的并发是很高的，统计并发最高的IP，加入黑名单（或者直接封掉爬虫IP所在C段）
- **请求的时间窗口过滤统计** 爬虫爬取网页的频率都是比较固定的，不像人去访问网页，中间的间隔时间比较无规则，所以我们可以给每个IP地址建立一个时间窗口，记录IP地址最近12次访问时间，每记录一次就滑动一次窗口，比较最近访问时间和当前时间，如果间隔时间很长判断不是爬虫，清除时间窗口，如果间隔不长，就回溯计算指定时间段的访问频率，如果访问频率超过阀值，就转向验证码页面让用户填写验证码
- **限制单个ip/api token的访问量** 比如15分钟限制访问页面180次，具体标准可参考一些大型网站的公开api，如twitter api，对于抓取用户公开信息的爬虫要格外敏感
- **识别出合法爬虫** 对http头agent进行验证，是否标记为、百度的spider，严格一点的话应该判别来源IP是否为、baidu的爬虫IP，这些IP在网上都可以找到。校验出来IP不在白名单就可以阻止访问内容。
- **蜜罐资源** 爬虫解析离不开正则匹配，适当在页面添加一些正常浏览器浏览访问不到的资源，一旦有ip访问，过滤下头部是不是搜素引擎的蜘蛛，不是就可以直接封了。比如说隐式链接。

#### 

![img](https://ask.qcloudimg.com/http-save/yehe-1227999/q183d3ozzp.jpeg)

#### 破解反爬虫机制的几种方法

- **策略1**：**设置下载延迟**，比如数字设置为5秒，越大越安全
- **策略2**：**禁止Cookie**，某些网站会通过Cookie识别用户身份，禁用后使得[服务器](https://cloud.tencent.com/act/pro/promotion-cvm?from_column=20065&from=20065)无法识别爬虫轨迹
- **策略3**：**使用user agent池**。也就是每次发送的时候随机从池中选择不一样的浏览器头信息，防止暴露爬虫身份
- **策略4**：**使用IP池**，这个需要大量的IP资源，可以通过抓取网上免费公开的IP建成自有的IP代理池。
- **策略5**：**分布式爬取**，这个是针对大型爬虫系统的，实现一个分布式的爬虫，主要为以下几个步骤：  1、基本的http抓取工具，如scrapy；  2、避免重复抓取网页，如Bloom Filter；  3、维护一个所有集群机器能够有效分享的分布式队列；  4、将分布式队列和Scrapy的结合；  5、后续处理，网页析取(如python-goose)，存储(如Mongodb)。
- **策略6：模拟登录—浏览器登录的爬取** 设置一个cookie处理对象，它负责将cookie添加到http请求中，并能从http响应中得到cookie，向网站登录页面发送一个请求Request, 包括登录url，POST请求的数据，Http header利用urllib2.urlopen发送请求，接收WEB服务器的Response。



设置ip代理
----------

[爬虫怎么在requests中设置自己clash软件的代理ip](https://blog.csdn.net/m0_56676945/article/details/129216849)

```python
import requests

proxies = {
    "http": "http://127.0.0.1:7890",
    "https": "http://127.0.0.1:7890",
}

response = requests.get("https://www.example.com", proxies=proxies)
```

交易猫注册
==========

项目信息
--------

### 号码

[接口文档](https://www.showdoc.com.cn/haozhuma/11176631946265944)

调用方法

`https://api.haozhuma.com/sms/?api=getPhone&token=707e8f8f4d86f7916e7a6e866e7700207baa3520&sid=20860&phone=号码`

### 代理ip

账号密码

zmhttp791203

Zz112211 

[接口文档](https://jahttp.zhimaruanjian.com/getapi/)

https://jahttp.zhimaruanjian.com/getapi/

代码
----

### [设置成手机模式启动](https://blog.csdn.net/qq_42623386/article/details/123391709)

浏览器
------

现在很多人在商用上都会考虑使用指纹浏览器ads，他如果配置得当以后，即使没有基础也能够实现轻松上手，它可以配置多个cookies，在启动多个浏览器，各个浏览器都使用独立的配置，这个本身`selenium`也可以实现，但是实现方法没有那么友好，对普通玩家不友好。之后我可以研究一下指纹浏览器的一些用法，我自己也可以使用这款浏览器。

接受短信验证码平台
==================

[LUBAN SMS](https://lubansms.com/v2/index?pid=1045&trade_no=2024080203355492579&out_trade_no=9502606680033876_315248&type=alipay&name=product&money=82.5&trade_status=TRADE_SUCCESS&sign=4829d828db020ad237f1dbc093020043&sign_type=MD5)

**查询余额请求**

接口 : http(s)://lubansms.com/v2/api/getBalance?apikey=YOUR_APIKEY

结果

{"code":0,"msg":"","balance":"96.72"}

可能的错误

{"code":400,"msg":"不正确的apikey"}



**请求号码**

接口 : http://lubansms.com/v2/api/getNumber?apikey=YOUR_APIKEY&service_id=service_id

参数

service_id(必填) ：服务编号,通过获取服务接口获取

结果

{"code":0,"msg":"","number":"79781901206","request_id":230698}

可能的错误

{"code":400,"msg":"不正确的apikey"}



**更改请求状态**

接口 : http(s)://lubansms.com/v2/api/setStatus?apikey=YOUR_APIKEY&request_id=13&status=status

参数

status(必填) ：值:reject 释放号码 类型:string

结果

{"code":0,"msg":"success"}

可能的错误

{"code":400,"msg":"不正确的apikey"}



**获取短信**

接口 : http(s)://lubansms.com/v2/api/getSms?apikey=YOUR_APIKEY&request_id=request_id

参数

request_id(必填) ：通过请求号码API得到的request_id

结果【等待短信】

{"code":0,"msg":"wait","sms_msg":{"request_id":"244936588","application_id":133,"country_id":1,"number":"79587588703"}}

结果【收到短信】

{"code":0,"msg":"success","sms_code":"380682"}

结果【号码已关闭(超时未收到)】

{"code":400,"msg":"wrong_status"}

可能的错误

{"code":400,"msg":"不正确的apikey"}



**获取国家列表**

接口 : http(s)://lubansms.com/v2/api/countries?apikey=YOUR_APIKEY

结果

{"code":0,"msg":[{"id":"1","name_en":"Russian Federation","name_cn":"俄罗斯","code":"RU"}]}

返回参数：id 为 获取号码接口的 country_id

可能的错误

{"code":400,"msg":"不正确的apikey"}



**获取服务列表**

接口 : http(s)://lubansms.com/v2/api/List?apikey=YOUR_APIKEY&country=countryName&service=serviceName&language=en&page=1

参数

country(选填) ：国家名称,例如 中文:美国 language参数对应zh 英文:USA language参数对应en

service(选填) ：服务名称,支持模糊搜索 例如: whatsapp 、微信

language(选填) ：语言 支持 zh、en ,country参数如果有填写,必须提交对应参数的语言

page(选填) ：页码,不填默认第一页

结果

{"code":0,"msg":[{"service_id":"121949","country_name_zh":"u8d8au5357","country_name_en":"Vietnam","service_name":"Tinder","provider":"maxsim","cost":0.27},{"service_id":"328373","country_name_zh":"u8d8au5357","country_name_en":"Vietnam","service_name":"Tinder","provider":"linesms","cost":0.24}]}

返回参数：service_id 是服务编号,用于请求号码接口

可能的错误

{"code":400,"msg":"不正确的apikey"}